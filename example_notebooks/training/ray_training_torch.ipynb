{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d9702e6",
   "metadata": {},
   "source": [
    "## ray training with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66331b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install 'ray[default]' --quiet\n",
    "!pip install tensorboardX --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "513cd9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import ray\n",
    "from ray.util.sgd.torch import TorchTrainer\n",
    "from ray.util.sgd.torch import TrainingOperator\n",
    "# https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py\n",
    "from ray.util.sgd.torch.resnet import ResNet18\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fd57a0",
   "metadata": {},
   "source": [
    "## initialize a remote Ray cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11003e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting pod ray-worker-5e72135e-563b-40c3-b148-cc539f2fda7b\n",
      "deleting pod ray-worker-6af3e495-afd7-4968-acdd-37975c8c1ace\n",
      "ðŸ‘‰ Hyperplane: selecting worker node pool\n",
      "best pool spec {'pool_env_var': 'DASK_POOL_16_16', 'allocatable_cores': 15.0, 'allocatable_ram': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-08 05:41:57,234\tWARNING services.py:1748 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=8.19gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for worker ray-worker-1274a214-9c4a-4935-b0be-8b7bca9a7175...\n",
      "Waiting for worker ray-worker-32267120-50f5-479e-b2e0-70873efba81a...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet, ip=10.1.157.3)\u001b[0m [2021-12-08 05:44:43,964 E 16 16] agent_manager.cc:134: Not all required Ray dependencies for the runtime_env feature were found. To install the required dependencies, please run `pip install 'ray[default]'`.\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.1.157.3)\u001b[0m [2021-12-08 05:44:43,964 E 16 16] worker_pool.cc:566: [Eagerly] Couldn't create a runtime environment for job 01000000.\n"
     ]
    }
   ],
   "source": [
    "from hyperplane.ray_common import initialize_ray_cluster, stop_ray_cluster, find_ray_workers\n",
    "num_workers = 2\n",
    "cpu_core_per_worker = 7\n",
    "ram_gb_per_worker = 6 #110 GB allocatible for 16_128 nodes, 12 for 16_16 nodes, 27 for 32_32 nodes\n",
    "ray_cluster = initialize_ray_cluster(num_workers, cpu_core_per_worker, ram_gb_per_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c05e726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifar_creator(config):\n",
    "    \"\"\"Returns dataloaders to be used in `train` and `validate`.\"\"\"\n",
    "    tfms = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                             (0.2023, 0.1994, 0.2010)),\n",
    "    ])  # meanstd transformation\n",
    "    train_loader = DataLoader(\n",
    "        CIFAR10(root=\"~/data\", download=True, transform=tfms), batch_size=config[\"batch\"])\n",
    "    validation_loader = DataLoader(\n",
    "        CIFAR10(root=\"~/data\", download=True, transform=tfms), batch_size=config[\"batch\"])\n",
    "    return train_loader, validation_loader\n",
    "\n",
    "def optimizer_creator(model, config):\n",
    "    \"\"\"Returns an optimizer (or multiple)\"\"\"\n",
    "    return torch.optim.SGD(model.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "CustomTrainingOperator = TrainingOperator.from_creators(\n",
    "    model_creator=ResNet18, # A function that returns a nn.Module\n",
    "    optimizer_creator=optimizer_creator, # A function that returns an optimizer\n",
    "    data_creator=cifar_creator, # A function that returns dataloaders\n",
    "    loss_creator=torch.nn.CrossEntropyLoss  # A loss function\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "872c6b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=55, ip=10.1.158.3)\u001b[0m 2021-12-08 05:45:12,295\tINFO distributed_torch_runner.py:58 -- Setting up process group for: tcp://10.1.158.3:37499 [rank=0]\n",
      "\u001b[2m\u001b[36m(pid=54, ip=10.1.157.3)\u001b[0m 2021-12-08 05:45:12,621\tINFO distributed_torch_runner.py:58 -- Setting up process group for: tcp://10.1.158.3:37499 [rank=1]\n",
      "0it [00:00, ?it/s]ip=10.1.158.3)\u001b[0m \n",
      "0it [00:00, ?it/s]ip=10.1.157.3)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DistributedTorchRunner pid=55, ip=10.1.158.3)\u001b[0m Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /root/data/cifar-10-python.tar.gz\n",
      "\u001b[2m\u001b[36m(DistributedTorchRunner pid=54, ip=10.1.157.3)\u001b[0m Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /root/data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/170498071 [00:00<?, ?it/s]\n",
      "  0%|          | 0/170498071 [00:00<?, ?it/s]\n",
      "  0%|          | 434176/170498071 [00:00<00:43, 3926175.35it/s]\n",
      "  0%|          | 434176/170498071 [00:00<00:44, 3825303.08it/s]\n",
      "  3%|â–Ž         | 4677632/170498071 [00:00<00:06, 25587248.60it/s]\n",
      "  2%|â–         | 3563520/170498071 [00:00<00:08, 19004184.77it/s]\n",
      "  6%|â–Œ         | 10182656/170498071 [00:00<00:04, 38470912.76it/s]\n",
      "  4%|â–         | 6725632/170498071 [00:00<00:06, 24562229.29it/s]\n",
      "  9%|â–‰         | 15458304/170498071 [00:00<00:03, 43997172.69it/s]\n",
      "  6%|â–Œ         | 9904128/170498071 [00:00<00:05, 27313987.95it/s]\n",
      " 12%|â–ˆâ–        | 20471808/170498071 [00:00<00:03, 46054359.53it/s]\n",
      "  8%|â–Š         | 13066240/170498071 [00:00<00:05, 28663002.55it/s]\n",
      " 15%|â–ˆâ–Œ        | 25829376/170498071 [00:00<00:02, 48473165.10it/s]\n",
      " 10%|â–‰         | 16310272/170498071 [00:00<00:05, 29828920.03it/s]\n",
      " 18%|â–ˆâ–Š        | 31006720/170498071 [00:00<00:02, 49532843.98it/s]\n",
      " 11%|â–ˆâ–        | 19472384/170498071 [00:00<00:04, 30315595.01it/s]\n",
      " 21%|â–ˆâ–ˆâ–       | 36380672/170498071 [00:00<00:02, 50856913.16it/s]\n",
      " 13%|â–ˆâ–Ž        | 22650880/170498071 [00:00<00:04, 30738076.00it/s]\n",
      " 25%|â–ˆâ–ˆâ–       | 41803776/170498071 [00:01<00:02, 51743323.44it/s]\n",
      " 15%|â–ˆâ–Œ        | 25681920/170498071 [00:01<00:04, 30582507.47it/s]\n",
      " 28%|â–ˆâ–ˆâ–Š       | 46981120/170498071 [00:01<00:02, 51653174.51it/s]\n",
      " 17%|â–ˆâ–‹        | 28860416/170498071 [00:01<00:04, 30873237.85it/s]\n",
      " 31%|â–ˆâ–ˆâ–ˆ       | 52142080/170498071 [00:01<00:02, 51608474.32it/s]\n",
      " 19%|â–ˆâ–Š        | 31956992/170498071 [00:01<00:04, 30840567.05it/s]\n",
      " 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 57466880/170498071 [00:01<00:02, 51891425.55it/s]\n",
      " 21%|â–ˆâ–ˆ        | 35119104/170498071 [00:01<00:04, 31061771.04it/s]\n",
      " 23%|â–ˆâ–ˆâ–Ž       | 38363136/170498071 [00:01<00:04, 31373007.26it/s]\n",
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 62799872/170498071 [00:01<00:02, 52323840.61it/s]\n",
      " 24%|â–ˆâ–ˆâ–       | 41656320/170498071 [00:01<00:04, 31833040.11it/s]\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–‰      | 68034560/170498071 [00:01<00:01, 52317914.67it/s]\n",
      " 26%|â–ˆâ–ˆâ–‹       | 44834816/170498071 [00:01<00:03, 31784933.71it/s]\n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 73375744/170498071 [00:01<00:01, 52520081.65it/s]\n",
      " 28%|â–ˆâ–ˆâ–Š       | 48062464/170498071 [00:01<00:03, 31887898.87it/s]\n",
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 78626816/170498071 [00:01<00:01, 52100517.57it/s]\n",
      " 30%|â–ˆâ–ˆâ–ˆ       | 51470336/170498071 [00:01<00:03, 32530176.59it/s]\n",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 83836928/170498071 [00:01<00:01, 51412164.11it/s]\n",
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 54796288/170498071 [00:01<00:03, 32593729.42it/s]\n",
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 88981504/170498071 [00:01<00:01, 51303983.78it/s]\n",
      " 34%|â–ˆâ–ˆâ–ˆâ–      | 58155008/170498071 [00:02<00:03, 32786058.85it/s]\n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 94199808/170498071 [00:02<00:01, 51421317.82it/s]\n",
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 63332352/170498071 [00:02<00:02, 38412729.46it/s]\n",
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 99885056/170498071 [00:02<00:01, 52887125.10it/s]\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 68796416/170498071 [00:02<00:02, 43258961.78it/s]\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 105340928/170498071 [00:02<00:01, 53377735.36it/s]\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 74235904/170498071 [00:02<00:02, 46588585.56it/s]\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 110764032/170498071 [00:02<00:01, 53628989.26it/s]\n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 79634432/170498071 [00:02<00:01, 48639293.26it/s]\n",
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 116187136/170498071 [00:02<00:01, 53644828.50it/s]\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 85057536/170498071 [00:02<00:01, 50225753.02it/s]\n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 121626624/170498071 [00:02<00:00, 53735478.30it/s]\n",
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 90497024/170498071 [00:02<00:01, 51362394.50it/s]\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 127066112/170498071 [00:02<00:00, 53823963.37it/s]\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 95805440/170498071 [00:02<00:01, 51664958.94it/s]\n",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 132456448/170498071 [00:02<00:00, 53487368.67it/s]\n",
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 100974592/170498071 [00:02<00:01, 51621980.54it/s]\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 137805824/170498071 [00:02<00:00, 52750349.35it/s]\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 106143744/170498071 [00:02<00:01, 51302718.72it/s]\n",
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 143089664/170498071 [00:02<00:00, 52453404.09it/s]\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 111280128/170498071 [00:03<00:01, 50858135.25it/s]\n",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 148340736/170498071 [00:03<00:00, 51552914.33it/s]\n",
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 116367360/170498071 [00:03<00:01, 50208117.75it/s]\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 153501696/170498071 [00:03<00:00, 50939275.92it/s]\n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 121397248/170498071 [00:03<00:00, 50106309.86it/s]\n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 158605312/170498071 [00:03<00:00, 50418407.46it/s]\n",
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 126410752/170498071 [00:03<00:00, 49481992.92it/s]\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 163651584/170498071 [00:03<00:00, 49736825.53it/s]\n",
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 131366912/170498071 [00:03<00:00, 49191889.77it/s]\n",
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 168632320/170498071 [00:03<00:00, 49362614.75it/s]\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 137076736/170498071 [00:03<00:00, 51511280.38it/s]\n",
      "170500096it [00:03, 48003598.12it/s]                               \n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 145006592/170498071 [00:03<00:00, 59729579.49it/s]\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 154263552/170498071 [00:03<00:00, 69487219.27it/s]\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 163504128/170498071 [00:03<00:00, 76302488.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DistributedTorchRunner pid=54, ip=10.1.157.3)\u001b[0m Extracting /root/data/cifar-10-python.tar.gz to /root/data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170500096it [00:03, 42925697.02it/s]                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DistributedTorchRunner pid=55, ip=10.1.158.3)\u001b[0m Extracting /root/data/cifar-10-python.tar.gz to /root/data\n",
      "\u001b[2m\u001b[36m(DistributedTorchRunner pid=54, ip=10.1.157.3)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(DistributedTorchRunner pid=55, ip=10.1.158.3)\u001b[0m Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainer = TorchTrainer(\n",
    "    training_operator_cls=CustomTrainingOperator,\n",
    "    config={\"lr\": 0.01, # used in optimizer_creator\n",
    "            \"batch\": 64 # used in data_creator\n",
    "           },\n",
    "    num_workers=2,  # amount of parallelism\n",
    "    use_gpu=torch.cuda.is_available(),\n",
    "    use_tqdm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df88a520",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = trainer.train()\n",
    "print(trainer.validate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d262cd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trainer.state_dict(), \"checkpoint.pt\")\n",
    "trainer.shutdown()\n",
    "print(\"success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b503483d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting ray-worker-1274a214-9c4a-4935-b0be-8b7bca9a7175\n",
      "Deleting ray-worker-32267120-50f5-479e-b2e0-70873efba81a\n"
     ]
    }
   ],
   "source": [
    "stop_ray_cluster(ray_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84100ef-d836-419a-81a7-b5320e42e694",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
